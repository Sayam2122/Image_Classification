# üõ∞Ô∏è Satellite Image Classifier - Usage Guide

## Quick Start

```bash
python satellite_classifier_hierarchical.py
```

## üìã How It Works

### 1Ô∏è‚É£ First Run - Training Mode
When you run the script for the first time (or when no trained model exists):

1. **Loads Training Data**
   - Reads from hierarchical folders: Urban/, Vegetation/, Water/
   - Custom samples per class: Urban 5000, Vegetation 6000, Water 5000 (16,000 total)
   - Equally distributed from subfolders within each class

2. **Feature Extraction**
   - Extracts **80 enhanced features** per image:
     * RGB statistics (18 features: mean, std, Q10, Q25, Q75, Q90 √ó 3 channels)
     * HSV color space (18 features: same statistics)
     * LAB color space (12 features: mean, std, Q25, Q75 √ó 3 channels)
     * Sobel gradients (8 features: magnitude and direction)
     * Edge features (6 features: density and percentiles)
     * Spatial quadrants (12 features: 4 quadrants √ó 3 stats)
     * Statistical moments (6 features: kurtosis, skew, variance, range, median, entropy)
   - Uses histogram equalization preprocessing

3. **Feature Selection**
   - Uses Jeffries-Matusita distance (optimized for satellite imagery)
   - Selects top **43 most discriminative features**
   - JM range: [0, 2] where 2 = perfect separability
   - Features ranked with descriptive names (e.g., "RGB_Blue_Mean", "HSV_Hue_Q10")

4. **Training**
   - Trains two classifiers:
     * Minimum Distance to Mean (MDC)
     * Maximum Likelihood (MLC - Gaussian)
   - 85%/15% train-test split
   - Computes class statistics (between/within class metrics)
   - Creates comprehensive visualizations

5. **Saves Model**
   - Saves to: `trained_model_hierarchical.pkl`
   - Contains: class means, covariances, scaler, selected features, accuracy metrics

‚è±Ô∏è **Training time: 1-2 minutes (optimized!)**

---

### 2Ô∏è‚É£ Subsequent Runs - Classification Mode
When trained model exists:

1. **Automatic Detection**
   ```
   üìÇ Found existing trained model: trained_model_hierarchical.pkl
   Load existing model and classify new image? (y/n):
   ```

2. **Load Model**
   - Loads instantly (< 1 second)
   - Shows trained classes and accuracy

3. **Classify Image**
   ```
   üì∑ Enter test image path (press Enter for default 'image3.jpg'):
   ```
   - Enter path to your test image (e.g., `image3.jpg`, `test/satellite.png`)
   - Or press Enter to use default

4. **Pixel-Level Classification** üé®
   - Divides image into 32√ó32 pixel patches
   - Classifies each patch independently using MDC and MLC
   - Generates color-coded classification maps:
     * üî¥ Red = Urban
     * üü¢ Green = Vegetation
     * üîµ Blue = Water

5. **Results & Visualization**
   ```
   üéØ Classification Results:
      Minimum Distance Classifier (MDC): Urban
      Maximum Likelihood Classifier (MLC): Urban ‚≠ê
   ```
   
   **Comprehensive visualization includes:**
   - Original test image
   - MDC pixel-level classification map with prediction
   - MLC pixel-level classification map with prediction
   - Overlay images (original + classification transparency)
   - Class legend with color codes
   - Pixel statistics showing class distribution percentages
   - All training analysis files (confusion matrices, feature analysis, class stats)

‚ö° **Classification time: ~30-60 seconds for full pixel-level analysis!**

---

## üìÅ File Structure

```
GNR_Project/
‚îú‚îÄ‚îÄ satellite_classifier_hierarchical.py  # Main script
‚îú‚îÄ‚îÄ trained_model_hierarchical.pkl        # Saved model (created after first run)
‚îú‚îÄ‚îÄ satellite/
‚îÇ   ‚îî‚îÄ‚îÄ EuroSAT/
‚îÇ       ‚îú‚îÄ‚îÄ Urban/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Highway/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Industrial/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Residential/
‚îÇ       ‚îú‚îÄ‚îÄ Vegetation/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ AnnualCrop/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Forest/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ HerbaceousVegetation/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Pasture/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ PermanentCrop/
‚îÇ       ‚îî‚îÄ‚îÄ Water/
‚îÇ           ‚îú‚îÄ‚îÄ River/
‚îÇ           ‚îî‚îÄ‚îÄ SeaLake/
‚îî‚îÄ‚îÄ output/
    ‚îî‚îÄ‚îÄ image3/
        ‚îú‚îÄ‚îÄ classified_result.png              # Comprehensive pixel-level visualization
        ‚îú‚îÄ‚îÄ accuracy_comparison.png            # Training accuracy comparison
        ‚îú‚îÄ‚îÄ confusion_matrices.png             # Confusion matrices (MDC & MLC)
        ‚îú‚îÄ‚îÄ class_statistics.png               # Between/within class analysis
        ‚îú‚îÄ‚îÄ feature_selection_analysis.png     # Top features visualization
        ‚îú‚îÄ‚îÄ feature_ranking.csv                # All 80 features ranked by JM distance
        ‚îî‚îÄ‚îÄ class_statistics.csv               # Class metrics and sample counts
```

---

## üîß Configuration

Edit these variables in `satellite_classifier_hierarchical.py`:

```python
SATELLITE_DATASET_PATH = "satellite/EuroSAT"     # Training data location
TEST_IMAGE_PATH = "image3.jpg"                    # Default test image
OUTPUT_FOLDER = "output/image3"                   # Results folder
MODEL_SAVE_PATH = "trained_model_hierarchical.pkl" # Model file
CLASS_SAMPLE_SIZES = {                            # Samples per class (customizable)
    'Urban': 5000,
    'Vegetation': 6000,
    'Water': 5000
}
NUM_BEST_FEATURES = 43                            # Number of features to select
IMAGE_SIZE = 32                                   # Image resize for feature extraction
TEST_SIZE = 0.15                                  # Test set proportion (15%)
```

---

## üìä Output Files

### Training Outputs (saved to both root and output folder):
1. **trained_model_hierarchical.pkl** - Trained model (reusable!)
2. **feature_ranking.csv** - All 80 features ranked by JM distance with descriptive names
3. **class_statistics.csv** - Between/within class statistics + sample counts
4. **accuracy_comparison.png** - Bar chart comparing MDC vs MLC
5. **confusion_matrices.png** - Side-by-side confusion matrices
6. **class_statistics.png** - Between-class separation & within-class variation bars
7. **feature_selection_analysis.png** - Top features with JM scores and distributions

### Classification Outputs:
8. **classified_result.png** - **NEW! Comprehensive pixel-level analysis:**
   - Original test image
   - MDC classification map (color-coded pixels)
   - MLC classification map (color-coded pixels)
   - Overlay visualizations (original + classification)
   - Class legend (Red=Urban, Green=Vegetation, Blue=Water)
   - Pixel statistics (percentage breakdown by class)

All files are saved to the output folder (e.g., `output/image3/`) with training analysis included!

---

## üí° Tips

### To Retrain Model:
1. Delete `trained_model_hierarchical.pkl`
2. Run the script again
3. Training files will be saved to both root directory and output folder

### To Classify Multiple Images:
Option 1: Run script multiple times, enter different paths
```bash
python satellite_classifier_hierarchical.py
# Enter: image1.jpg (creates output/image1/)
python satellite_classifier_hierarchical.py  
# Enter: image2.jpg (creates output/image2/)
```

Option 2: Change `TEST_IMAGE_PATH` in the script

### Understanding Pixel-Level Classification:
- **Patch size**: 32√ó32 pixels (configurable for speed vs detail)
- **Color coding**: 
  - üî¥ Red pixels = Classified as Urban
  - üü¢ Green pixels = Classified as Vegetation  
  - üîµ Blue pixels = Classified as Water
- **Overlay mode**: Shows classification transparency over original image
- **Statistics**: Shows percentage of pixels in each class

### To Adjust Classification Speed:
In the classification section, change `patch_size`:
- `patch_size = 16` ‚Üí More detail, slower (4x patches)
- `patch_size = 32` ‚Üí Balanced (default)
- `patch_size = 64` ‚Üí Faster, less detail

---

## üéØ Expected Accuracy

- **Maximum Likelihood (MLC)**: 75-85% (recommended) ‚≠ê
- **Minimum Distance (MDC)**: 55-65%

Current model performance: **~80.58% accuracy** with 16,000 training samples!

Higher accuracy with:
- More training samples per class
- Better quality/resolution images
- More discriminative features
- Balanced class distribution

---

## üöÄ Speed Optimizations

Already implemented:
- ‚úÖ 80 enhanced features (comprehensive yet efficient)
- ‚úÖ Only Jeffries-Matusita distance (no redundant methods) ‚Üí 75% faster
- ‚úÖ 16,000 balanced samples (optimal speed/accuracy tradeoff)
- ‚úÖ Model persistence (no retraining needed!)
- ‚úÖ 32√ó32 image resizing for fast feature extraction
- ‚úÖ Optimized patch-based classification (32√ó32 patches)
- ‚úÖ Efficient feature extraction without temporary files

Training: **~80 seconds** | Classification: **~30-60 seconds** (depending on image size)

---

## ‚ùì Troubleshooting

**Problem**: Model file not found
- **Solution**: Run training first (answer 'n' when asked to load model)

**Problem**: Image not found during classification
- **Solution**: Check image path, use absolute path if needed

**Problem**: Out of memory during training
- **Solution**: Reduce sample sizes in `CLASS_SAMPLE_SIZES` dict (e.g., 3000 each)

**Problem**: Classification too slow
- **Solution**: Increase `patch_size` from 32 to 64 (faster but less detailed)

**Problem**: Training files not showing in classification output
- **Solution**: Delete `trained_model_hierarchical.pkl` and retrain to generate files

**Problem**: Features not displaying proper names
- **Solution**: Check `get_feature_names()` function returns 80 feature names

**Problem**: RuntimeWarning about precision loss in moments
- **Solution**: Ignore - this happens with uniform color patches and doesn't affect results

---

## üÜï New Features

### Version 2.0 Updates:
‚ú® **Pixel-Level Classification Maps** - See which pixels are Urban/Vegetation/Water  
‚ú® **80 Enhanced Features** - Added LAB color space and enhanced statistics  
‚ú® **Descriptive Feature Names** - "RGB_Blue_Mean" instead of "Feature_10"  
‚ú® **Comprehensive Visualization** - 6-panel layout with overlays and statistics  
‚ú® **Training Analysis Included** - All training files copied to classification output  
‚ú® **Class-Specific Sampling** - Different sample sizes per class for better balance  
‚ú® **43 Best Features** - Optimal feature count for accuracy/speed  

---

## üìû Summary

1. **First time**: Train once (~80 seconds), model saved automatically
2. **Every time after**: Load model instantly, get pixel-level classification in ~30-60 seconds
3. **No need to retrain** unless you want to change training data or parameters
4. **Complete analysis package** - All visualizations, confusion matrices, and statistics included!

üéâ **Enjoy comprehensive satellite image classification with pixel-level mapping!**
